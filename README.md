# ğŸ« Chocolate Recognition with Deep Learning
## IAPR 2025 Final Project - Group 1

A computer vision system for automated chocolate detection and classification using deep learning, achieving ~87% accuracy on the Kaggle leaderboard.

## ğŸ“‹ Project Overview

This project tackles the challenging task of automatically detecting and counting 13 different types of chocolates in high-resolution images. We implemented a two-stage deep learning pipeline:

1. **U-Net** for chocolate segmentation (localization)
2. **CNN** for chocolate type classification

### ğŸ¯ Key Achievements
- **99.5%** classification accuracy on individual chocolates
- **99.2%** ROC AUC for segmentation performance  
- **87%** end-to-end system accuracy on test set
- Fully automated pipeline from raw images to submission file

## ğŸ‘¥ Team Members
- **Alessio Zazo** 
- **Gautier Demierre** 
- **Georg Schwabedal** 

## ğŸ† Competition Details

**Track:** Deep Learning (Machine Learning Track)  
**Platform:** Kaggle - [Chocolate Recognition ML](https://www.kaggle.com/competitions/chocolate-recognition-ml)  
**Kaggle Team:** group 1

## ğŸš€ Quick Start

### Environment Setup

Using conda (recommended):
```bash
conda env create -f environment.yml
conda activate iapr_project
```

Using pip:
```bash
pip install -r requirements.txt
```

### Generate Submission

To reproduce our Kaggle submission:
```bash
python main.py
```

This will generate `submission.csv` with chocolate counts for all 180 test images.

### Verify Submission

Check submission validity:
```bash
python check.py check --path submission.csv
```

Compare with Kaggle submission:
```bash
python check.py match --local submission.csv --kaggle kaggle.csv
```

## ğŸ“ Project Structure

```
ğŸ“¦ chocolate-recognition/
â”œâ”€â”€ ğŸ“„ main.py                 # Main pipeline - generates submission.csv
â”œâ”€â”€ ğŸ“„ check.py                # Submission validation tool
â”œâ”€â”€ ğŸ“„ report.ipynb            # Detailed project report with visualizations
â”œâ”€â”€ ğŸ“„ report.pdf              # PDF version of the report
â”œâ”€â”€ ğŸ“„ environment.yml         # Conda environment configuration
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ“„ sample_submission.csv   # Submission format example
â”œâ”€â”€ ğŸ“„ submission.csv          # Generated predictions (after running main.py)
â”‚
â””â”€â”€ ğŸ“ src/                    # Source code and data
    â”œâ”€â”€ ğŸ“ models/             # Trained model weights
    â”‚   â”œâ”€â”€ ğŸ“ UNET/          
    â”‚   â”‚   â””â”€â”€ unet_final.pth           # U-Net segmentation model
    â”‚   â””â”€â”€ ğŸ“ CNN/           
    â”‚       â””â”€â”€ chocolate_classifier_final.pth  # CNN classifier
    â”‚
    â”œâ”€â”€ ğŸ“ data/               # Datasets and annotations
    â”‚   â”œâ”€â”€ ğŸ“ dataset_project_iapr2025/  # Original dataset
    â”‚   â”‚   â”œâ”€â”€ ğŸ“ train/                 # 90 training images
    â”‚   â”‚   â”œâ”€â”€ ğŸ“ test/                  # 180 test images
    â”‚   â”‚   â””â”€â”€ ğŸ“ reference_images/      # 13 chocolate references
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“ synthetic_UNET/   # Generated training data for U-Net
    â”‚   â”‚   â”œâ”€â”€ ğŸ“ images/       # 1000 synthetic images
    â”‚   â”‚   â””â”€â”€ ğŸ“ masks/        # Corresponding binary masks
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“ synthetic_CNN/    # Generated patches for CNN
    â”‚   â”‚   â””â”€â”€ [13,000 chocolate patches, 1000 per class]
    â”‚   â”‚
    â”‚   â””â”€â”€ labels_mask_ai.json  # Manual COCO annotations
    â”‚
    â””â”€â”€ ğŸ“ utils/              # Helper functions
        â”œâ”€â”€ data_preparation.py
        â”œâ”€â”€ model_architectures.py
        â””â”€â”€ inference.py
```

## ğŸ”¬ Methodology

### 1. Data Preparation
- **Manual Annotation**: 90 training images annotated using Mask AI platform
- **Synthetic Data Generation**: 
  - 1,000 synthetic images for U-Net training
  - 13,000 chocolate patches (1,000 per class) for CNN training
- **Data Augmentation**: Random rotations and placements

### 2. Model Architecture

#### U-Net (Segmentation)
- **Architecture**: 4-level encoder-decoder with skip connections
- **Input**: 256Ã—256 RGB images
- **Output**: Binary segmentation masks
- **Parameters**: 7.8M
- **Performance**: IoU = 0.90, Dice = 0.95

#### CNN (Classification)  
- **Architecture**: 4 convolutional blocks + 2 FC layers
- **Input**: 224Ã—224 chocolate patches
- **Output**: 13-class predictions
- **Performance**: 99.5% accuracy

### 3. Inference Pipeline

```python
Test Image â†’ U-Net Segmentation â†’ Blob Detection â†’ 
Splitting Algorithm â†’ Patch Extraction â†’ CNN Classification â†’ 
Chocolate Counting â†’ Submission File
```

Key components:
- **Blob Splitting**: Custom algorithm to separate touching chocolates
- **Convexity Analysis**: Identifies and splits merged chocolates
- **High-Resolution Processing**: Maintains detail for classification

## ğŸ“Š Performance Metrics

### Segmentation (U-Net)
| Metric | Score |
|--------|-------|
| IoU | 0.90 |
| Dice | 0.95 |
| Precision | 0.92 |
| Recall | 0.97 |
| ROC AUC | 0.99 |

### Classification (CNN)
| Metric | Score |
|--------|-------|
| Accuracy | 99.50% |
| Precision | 99.52% |
| Recall | 99.47% |
| F1-Score | 99.48% |

### End-to-End System
- **Public Leaderboard**: ~87% accuracy
- **Main Challenge**: Blob splitting for touching chocolates

## ğŸ« Chocolate Classes

The 13 chocolate varieties we classify:
1. Jelly White
2. Jelly Milk  
3. Jelly Black
4. Amandina
5. CrÃ¨me brulÃ©e
6. Triangolo
7. Tentation noir
8. Comtesse
9. Noblesse
10. Noir authentique
11. Passion au lait
12. Arabia
13. Stracciatella

## âš™ï¸ Technical Requirements

- Python 3.9.x
- PyTorch with CUDA support (recommended)
- 8GB+ RAM
- GPU with 4GB+ VRAM (optional but recommended)

Key dependencies:
- torch, torchvision
- numpy, pandas
- opencv-python, PIL
- scikit-learn, scipy
- matplotlib, seaborn

## ğŸ“ Learning Outcomes

This project demonstrated:
- **Integration Challenges**: Individual component excellence doesn't guarantee system-level performance
- **Edge Cases Matter**: Handling touching chocolates proved critical
- **Trade-offs**: Balance between processing efficiency (256Ã—256) and detail preservation
- **Data Generation**: Synthetic data effectively augmented limited training samples

## ğŸ”® Future Improvements

1. **Advanced Segmentation**: Instance segmentation (Mask R-CNN) instead of semantic segmentation
2. **Better Splitting**: Machine learning-based chocolate separation
3. **Higher Resolution**: Process at original resolution despite computational cost
4. **End-to-End Training**: Joint optimization of detection and classification
5. **Post-Processing**: Validation layer to filter false positives

## ğŸ“š References

- Original U-Net paper: [Ronneberger et al., 2015](https://arxiv.org/abs/1505.04597)
- Instance Segmentation: [Mask R-CNN](https://arxiv.org/abs/1703.06870)
- COCO Format: [COCO Dataset](https://cocodataset.org/#format-data)

## ğŸ“ Notes

- The complete pipeline takes ~30 minutes to process all test images
- Pre-trained weights are included for reproducibility
- Training from scratch requires ~2-3 hours on GPU
- Manual annotations available in COCO format

## ğŸ¤ Acknowledgments

- EPFL IAPR Course Team for project organization
- Mask AI platform for annotation tools
- Kaggle for hosting the competition

---

*For detailed implementation and results, please refer to `report.ipynb` or `report.pdf`*